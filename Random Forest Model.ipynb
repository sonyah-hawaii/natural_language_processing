{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi = pd.read_csv('Xi.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We're going to do some quick cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Yi that will be put into my K-Means method\n",
    "Yi = np.sqrt(Xi[[\n",
    "    'comments'\n",
    "]])\n",
    "\n",
    "X = Xi.drop(labels=['score','gilded','ups','downs'], axis=1)\n",
    "#creating a new X dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['distinguished'].fillna(value=0, inplace=True)\n",
    "#correcting the NaNs for 0's to signify non-moderator\n",
    "\n",
    "X['distinguished'].replace('moderator', 1, inplace=True)\n",
    "#filling in 1's for moderator status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit_type\n",
      "over_18\n",
      "distinguished\n",
      "stickied\n",
      "locked\n",
      "is_video\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import scipy\n",
    "\n",
    "bools = ['subreddit_type','over_18','distinguished',\n",
    "         'stickied','locked','is_video']\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "for column in X[bools]:\n",
    "    print(column)\n",
    "    try:\n",
    "        lb.fit(X[column])\n",
    "        X[column] = lb.transform(X[column])\n",
    "    except ValueError:\n",
    "        print(column+' needs cleaning!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Yi,\n",
    "                                               random_state=1994,\n",
    "                                                test_size=0.3,\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2, #2 clusters for binary output\n",
    "               random_state = 1994,\n",
    "               )\n",
    "target_train = kmeans.fit_predict(trainY)\n",
    "target_test = kmeans.predict(testY)\n",
    "Xi['target'] = kmeans.predict(Yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 4.30142428, 22.19539655]), 'comments')]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(kmeans.cluster_centers_.T, Yi.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comments                   int64\n",
       "title                     object\n",
       "subreddit                 object\n",
       "subreddit_subscribers      int64\n",
       "subreddit_type             int64\n",
       "time_since_posted        float64\n",
       "over_18                    int64\n",
       "distinguished              int64\n",
       "stickied                   int64\n",
       "locked                     int64\n",
       "num_crossposts             int64\n",
       "is_video                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_numeric= trainX.drop(labels=['title','subreddit'], axis=1)\n",
    "testX_numeric = testX.drop(labels=['title','subreddit'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(trainX_numeric, target_train)\n",
    "rf.score(testX_numeric, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.40944848e-01, 1.85557843e-02, 1.47036547e-04, 2.64383411e-03,\n",
       "       2.74844565e-04, 5.71667365e-04, 6.29841552e-04, 2.21877795e-03,\n",
       "       3.39139269e-02, 9.94382953e-05])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = trainX_numeric.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "#script courtesy of Sam because I was too lazy to rewrite my exp_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>0.940945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_crossposts</th>\n",
       "      <td>0.033914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <td>0.018556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_posted</th>\n",
       "      <td>0.002644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locked</th>\n",
       "      <td>0.002219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stickied</th>\n",
       "      <td>0.000630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distinguished</th>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over_18</th>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_type</th>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_video</th>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance\n",
       "comments                 0.940945\n",
       "num_crossposts           0.033914\n",
       "subreddit_subscribers    0.018556\n",
       "time_since_posted        0.002644\n",
       "locked                   0.002219\n",
       "stickied                 0.000630\n",
       "distinguished            0.000572\n",
       "over_18                  0.000275\n",
       "subreddit_type           0.000147\n",
       "is_video                 0.000099"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because comments is highest, I'm going to try this again without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = Xi.drop(labels=['score','gilded','ups','downs', 'comments','target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit_type\n",
      "over_18\n",
      "distinguished\n",
      "stickied\n",
      "locked\n",
      "is_video\n"
     ]
    }
   ],
   "source": [
    "X_2['distinguished'].fillna(value=0, inplace=True)\n",
    "#correcting the NaNs for 0's to signify non-moderator\n",
    "\n",
    "X_2['distinguished'].replace('moderator', 1, inplace=True)\n",
    "#filling in 1's for moderator status\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "for column in X_2[bools]:\n",
    "    print(column)\n",
    "    try:\n",
    "        lb.fit(X_2[column])\n",
    "        X_2[column] = lb.transform(X_2[column])\n",
    "    except ValueError:\n",
    "        print(column+' needs cleaning!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_2, testX_2, trainY_2, testY_2 = train_test_split(X_2, Yi,\n",
    "                                               random_state=1994,\n",
    "                                                test_size=0.3,\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 2, #2 clusters for binary output\n",
    "               random_state = 1994,\n",
    "               )\n",
    "target_train_2 = kmeans.fit_predict(trainY)\n",
    "target_test_2 = kmeans.predict(testY)\n",
    "Xi['target'] = kmeans.predict(Yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 4.30142428, 22.19539655]), 'comments')]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(kmeans.cluster_centers_.T, Yi.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_2_numeric= trainX_2.drop(labels=['title','subreddit'], axis=1)\n",
    "testX_2_numeric = testX_2.drop(labels=['title','subreddit'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9408065112837588"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_2 = RandomForestClassifier()\n",
    "rf_2.fit(trainX_2_numeric, target_train_2)\n",
    "rf_2.score(testX_2_numeric, target_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <td>0.800607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_crossposts</th>\n",
       "      <td>0.163945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_posted</th>\n",
       "      <td>0.013053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_video</th>\n",
       "      <td>0.007306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locked</th>\n",
       "      <td>0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over_18</th>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stickied</th>\n",
       "      <td>0.003014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distinguished</th>\n",
       "      <td>0.002144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_type</th>\n",
       "      <td>0.001181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance\n",
       "subreddit_subscribers    0.800607\n",
       "num_crossposts           0.163945\n",
       "time_since_posted        0.013053\n",
       "is_video                 0.007306\n",
       "locked                   0.004722\n",
       "over_18                  0.004028\n",
       "stickied                 0.003014\n",
       "distinguished            0.002144\n",
       "subreddit_type           0.001181"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_2 = pd.DataFrame(rf_2.feature_importances_,\n",
    "                                   index = trainX_2_numeric.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "#script courtesy of Sam because I was too lazy to rewrite my exp_coeff\n",
    "\n",
    "feature_importances_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My score wasn't great, so I am going to try to run a `GridSearch` on it and see if we can improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941801458928005\n",
      "{'max_depth': 6, 'max_features': 8, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators':[40,50,60],\n",
    "    'max_features':[7,8,9],\n",
    "    'max_depth':[4,5,6]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf_2, param_grid = rf_params)\n",
    "gs.fit(trainX_2_numeric, target_train_2)\n",
    "gs.score(testX_2_numeric, target_test_2)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at our importances with a model optimized by `GridSearch`\n",
    "#### Also note, I ran a few `GridSearch` and changed the params around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_3 = RandomForestClassifier(max_features=9,\n",
    "                             n_estimators=50,\n",
    "                             max_depth=6)\n",
    "rf_3.fit(trainX_2_numeric, target_train_2)\n",
    "rf_3.score(testX_2_numeric, target_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I haven't worked much with trees so I am sure this is not entirely solid in practice, but I'm going to accept this 0.001 improvement on my score and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <td>0.800607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_crossposts</th>\n",
       "      <td>0.163945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_posted</th>\n",
       "      <td>0.013053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_video</th>\n",
       "      <td>0.007306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locked</th>\n",
       "      <td>0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over_18</th>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stickied</th>\n",
       "      <td>0.003014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distinguished</th>\n",
       "      <td>0.002144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_type</th>\n",
       "      <td>0.001181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance\n",
       "subreddit_subscribers    0.800607\n",
       "num_crossposts           0.163945\n",
       "time_since_posted        0.013053\n",
       "is_video                 0.007306\n",
       "locked                   0.004722\n",
       "over_18                  0.004028\n",
       "stickied                 0.003014\n",
       "distinguished            0.002144\n",
       "subreddit_type           0.001181"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_3 = pd.DataFrame(rf_2.feature_importances_,\n",
    "                                   index = trainX_2_numeric.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "#script courtesy of Sam because I was too lazy to rewrite my exp_coeff\n",
    "\n",
    "feature_importances_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After this, for fun, I explored a multi-class output. It wasn't a fruitful endeavor so I deleted that portion of the notebook. I know I could have, and should have, developed `Pipelines` considering how many times I ran these models, but I didn't. I was more focused on creating a coherent set of notebooks for now. The `pipeline_development` notebook is empty.\n",
    "#### That concludes my project 3. Thanks for grading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
